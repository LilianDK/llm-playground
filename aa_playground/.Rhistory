token = "eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJ1c2VyX2lkIjo0MjcyLCJ0b2tlbl9pZCI6MjgxMX0.k1PwaELDM-EKCWq9gPwkgtWA6bdo50gzoFb8Q3lOobk"
list = aa_completion(token = token,
prompt = "Q:How are you?###A:",
model = "luminous-extended",
stop_sequences = "###",
maximum_tokens = 124)
token = "eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJ1c2VyX2lkIjo0MjcyLCJ0b2tlbl9pZCI6MjgxMX0.k1PwaELDM-EKCWq9gPwkgtWA6bdo50gzoFb8Q3lOobk"
list = aa_completion(token = token,
prompt = "Q:How are you?###A",
model = "luminous-extended",
stop_sequences = "###",
maximum_tokens = 124)
token = "eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJ1c2VyX2lkIjo0MjcyLCJ0b2tlbl9pZCI6MjgxMX0.k1PwaELDM-EKCWq9gPwkgtWA6bdo50gzoFb8Q3lOobk"
list = aa_completion(token = token,
prompt = "Q:How are you?###A", model = "luminous-extended",stop_sequences = "###",maximum_tokens = 124)
token = "eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJ1c2VyX2lkIjo0MjcyLCJ0b2tlbl9pZCI6MjgxMX0.k1PwaELDM-EKCWq9gPwkgtWA6bdo50gzoFb8Q3lOobk"
list = aa_completion(token = token,
prompt = "Q:How are you?###A", model = "luminous-extended",stop_sequences = "###",maximum_tokens = 124)
list = aa_completion(token = token,
prompt = "Q:How are you?###A", model = "luminous-extended",maximum_tokens = 124)
list = aa_completion(token = token,
prompt = "Q:How are you?###A", model = "luminous-extended",stop_sequence = "###",maximum_tokens = 124)
token = "eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJ1c2VyX2lkIjo0MjcyLCJ0b2tlbl9pZCI6MjgxMX0.k1PwaELDM-EKCWq9gPwkgtWA6bdo50gzoFb8Q3lOobk"
list = aa_completion(token = token,
prompt = "Q:How are you?###A", model = "luminous-extended", stop_sequence = c("###"),maximum_tokens = 124)
list = aa_completion(token = token,
prompt = "Q:How are you?###A", model = "luminous-extended", stop_sequence = stoop,maximum_tokens = 124)
stoop = "###"
token = "eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJ1c2VyX2lkIjo0MjcyLCJ0b2tlbl9pZCI6MjgxMX0.k1PwaELDM-EKCWq9gPwkgtWA6bdo50gzoFb8Q3lOobk"
list = aa_completion(token = token,
prompt = "Q:How are you?###A", model = "luminous-extended", stop_sequence = stoop,maximum_tokens = 124)
token = "eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJ1c2VyX2lkIjo0MjcyLCJ0b2tlbl9pZCI6MjgxMX0.k1PwaELDM-EKCWq9gPwkgtWA6bdo50gzoFb8Q3lOobk"
list = aa_completion(token = token,
prompt = "Q:How are you?###A", model = "luminous-extended", stop_sequences = stoop,maximum_tokens = 124)
token = "eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJ1c2VyX2lkIjo0MjcyLCJ0b2tlbl9pZCI6MjgxMX0.k1PwaELDM-EKCWq9gPwkgtWA6bdo50gzoFb8Q3lOobk"
list = aa_completion(token = token,
prompt = "Q:How are you?###A", stop_sequences = stoop,model = "luminous-extended", maximum_tokens = 124)
token = "eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJ1c2VyX2lkIjo0MjcyLCJ0b2tlbl9pZCI6MjgxMX0.k1PwaELDM-EKCWq9gPwkgtWA6bdo50gzoFb8Q3lOobk"
list = aa_completion(token = token,
prompt = "Q:How are you?###A", model = "luminous-extended", maximum_tokens = 124,stop_sequences = stoop)
token = "eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJ1c2VyX2lkIjo0MjcyLCJ0b2tlbl9pZCI6MjgxMX0.k1PwaELDM-EKCWq9gPwkgtWA6bdo50gzoFb8Q3lOobk"
list = aa_completion(token = token,
prompt = "Q:How are you?###A", model = "luminous-extended", maximum_tokens = 124)
install_github("momper14/alephAlphaClient")
library(devtools)
install_github("momper14/alephAlphaClient")
install_github("momper14/alephAlphaClient", force = TRUE)
detach("alephAlphaClient", unload = TRUE)
detach("package:alephAlphaClient", unload = TRUE)
library(alephAlphaClient)
runApp()
runApp()
shiny::runApp()
runApp()
aa_completion(token = token,
prompt = "Q: How are you?",
model = "luminous-base",
maximum_tokens = 124,
best_of = 1,
temperature = 0,
top_k = 0,
top_p = 0,
frequency_penalty = 0,
presence_penalty = 0)
token = "eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJ1c2VyX2lkIjo0MjcyLCJ0b2tlbl9pZCI6MjgxMX0.k1PwaELDM-EKCWq9gPwkgtWA6bdo50gzoFb8Q3lOobk"
aa_completion(token = token,
prompt = "Q: How are you?",
model = "luminous-base",
maximum_tokens = 124,
best_of = 1,
temperature = 0,
top_k = 0,
top_p = 0,
frequency_penalty = 0,
presence_penalty = 0)
token = "eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJ1c2VyX2lkIjo0MjcyLCJ0b2tlbl9pZCI6MjgxMX0.k1PwaELDM-EKCWq9gPwkgtWA6bdo50gzoFb8Q3lOobk"
aa_completion(token = token,
prompt = "Q: How are you?",
model = "luminous-base",
maximum_tokens = 124)
aa_completion(token = token,
prompt = "Q: How are you?",
model = "luminous-base",
maximum_tokens = 124,
best_of = 1)
token = "eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJ1c2VyX2lkIjo0MjcyLCJ0b2tlbl9pZCI6MjgxMX0.k1PwaELDM-EKCWq9gPwkgtWA6bdo50gzoFb8Q3lOobk"
list = aa_completion(token = token,
prompt = "Q: How are you?",
model = "luminous-base",
stop_sequences = "")
token = "eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJ1c2VyX2lkIjo0MjcyLCJ0b2tlbl9pZCI6MjgxMX0.k1PwaELDM-EKCWq9gPwkgtWA6bdo50gzoFb8Q3lOobk"
list = aa_completion(token = token,
prompt = "Q: How are you?",
model = "luminous-base",
stop_sequences = "",
maximum_tokens = 1)
aa_completion(token = token,
prompt = "Q: How are you?",
model = "luminous-base",
stop_sequences = "",
maximum_tokens = 1)
aa_completion(token = token,
prompt = glue("You are a childish chatbot. Answer from the given input text.### Instruction:{input$prompt}###Input:Albert Einstein wasa physicist### Response:"),
model = "luminous-extended-control",
maximum_tokens = 124)
library(glue)
chatGPT1 <- aa_completion(token = token,
prompt = glue("You are a childish chatbot. Answer from the given input text.### Instruction:{input$prompt}###Input:Albert Einstein wasa physicist### Response:"),
model = "luminous-extended-control",
maximum_tokens = 124)
library(glue)
chatGPT1 <- aa_completion(token = token,
prompt = glue("You are a childish chatbot. Answer from the given input text.### Instruction:Test###Input:Albert Einstein wasa physicist### Response:"),
model = "luminous-extended-control",
maximum_tokens = 124)
chatGPT1
list = aa_completion(token = token,
prompt = "Q: How are you?",
model = "luminous-base",
maximum_tokens = 1)
token = "eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJ1c2VyX2lkIjo0MjcyLCJ0b2tlbl9pZCI6MjgxMX0.k1PwaELDM-EKCWq9gPwkgtWA6bdo50gzoFb8Q3lOobk"
list = aa_completion(token = token,
prompt = "Q: How are you?",
model = "luminous-base",
maximum_tokens = 1,
best_of = 1,
temperature = 0,
top_k = 0,
top_p = 0,
frequency_penalty = 0,
presence_penalty = 0)
chatGPT1 <- aa_completion(token = token,
prompt = glue("You are a childish chatbot. Answer from the given input text.### Instruction:Test###Input:Albert Einstein wasa physicist### Response:"),
model = "luminous-extended-control",
maximum_tokens = 124)
list = aa_completion(token = token,
prompt = "Q: How are you?",
model = "luminous-base",
maximum_tokens = 1,
best_of = 1,
temperature = 0,
top_k = 0,
top_p = 0,
frequency_penalty = 0,
presence_penalty = 0)
list = aa_completion(token = token,
prompt = "Q: How are you?",
model = "luminous-base",
maximum_tokens = 1,
best_of = 1)
list = aa_completion(token = token,
prompt = "Q: How are you?",
model = "luminous-base",
browser(),
maximum_tokens = 1,
best_of = 1)
library(reticulate)
py_install("aleph-alpha-client")
aaclient <- import("aleph-alpha-client")
aaclient <- import("Client")
import pandas
repl_python()
quit
use_python("/usr/local/bin/python")
use_virtualenv("myenv")
py_run_file("script.py")
py_run_file("/Users/dradecic/Desktop/script.py")
getwd()
py_run_file(glue("{x}/aa_client.py"))
x = getwd()
x
py_run_file(glue("{x}/aa_client.py"))
py_run_file(glue("{x}/aa_client.py"))
glue("{x}/aa_client.py")
py_run_file(glue("{x}/aa_client.py"))
x = getwd()
x
glue("{x}/aa_client.py")
reticulate::py_last_error()
py_run_file(glue("{x}/aa_client.py"))
py_run_file(glue("{x}/aa_client.py"))
completion()
py_run_file(glue("{x}/aa_client.py"))
completion()
library(reticulate)
py_run_file(glue("{x}/aa_client.py"))
completion()
source("aa_client.py")
source_python("aa_client.py")
py_run_file(glue("{x}/aa_client.py"))
completion()
prompt = "How are you"
model = "luminous-base"
stop_sequences ="###"
maximum_tokens = 3
best_of = 1
temperature = 0
top_k = 0
top_p = 0
presence_penalty = 0
frequency_penalty = 0
completion(token, prompt, model, stop_sequences, maximum_tokens, best_of, temperature, top_k, top_p, presence_penalty, frequency_penalty)
token = "eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJ1c2VyX2lkIjo0MjcyLCJ0b2tlbl9pZCI6MjgxMX0.k1PwaELDM-EKCWq9gPwkgtWA6bdo50gzoFb8Q3lOobk"
completion(token, prompt, model, stop_sequences, maximum_tokens, best_of, temperature, top_k, top_p, presence_penalty, frequency_penalty)
completion(token, prompt, model, stop_sequences, maximum_tokens, best_of, temperature, top_k, top_p, presence_penalty, frequency_penalty)
reticulate::py_last_error()
completion(token, prompt, model, stop_sequences, maximum_tokens, best_of, temperature, top_k, top_p, presence_penalty, frequency_penalty)
maximum_tokens = 33
completion(token, prompt, model, stop_sequences, maximum_tokens, best_of, temperature, top_k, top_p, presence_penalty, frequency_penalty)
typeof(maximum_tokens)
maximum_tokens = as.numeric(33)
typeof(maximum_tokens)
maximum_tokens = as.integer(33)
typeof(maximum_tokens)
best_of = 1
temperature = 0
top_k = 0
top_p = 0
presence_penalty = 0
frequency_penalty = 0
completion(token, prompt, model, stop_sequences, maximum_tokens, best_of, temperature, top_k, top_p, presence_penalty, frequency_penalty)
maximum_tokens = as.integer(33)
typeof(maximum_tokens)
best_of = as.integer(1)
temperature = 0
top_k = as.integer(0)
top_p = 0
presence_penalty = 0
frequency_penalty = 0
completion(token, prompt, model, stop_sequences, maximum_tokens, best_of, temperature, top_k, top_p, presence_penalty, frequency_penalty)
completion(token, prompt, model, stop_sequences, maximum_tokens, best_of, temperature, top_k, top_p, presence_penalty, frequency_penalty)
best_of = as.integer(0)
completion(token, prompt, model, stop_sequences, maximum_tokens, best_of, temperature, top_k, top_p, presence_penalty, frequency_penalty)
best_of = as.integer(5)
temperature = 0
top_k = as.integer(0)
top_p = 0
presence_penalty = 0
frequency_penalty = 0
completion(token, prompt, model, stop_sequences, maximum_tokens, best_of, temperature, top_k, top_p, presence_penalty, frequency_penalty)
best_of = as.integer(2)
temperature = 0
top_k = as.integer(0)
top_p = 0
presence_penalty = 0
frequency_penalty = 0
completion(token, prompt, model, stop_sequences, maximum_tokens, best_of, temperature, top_k, top_p, presence_penalty, frequency_penalty)
best_of = as.integer(1)
temperature = 0
top_k = as.integer(0)
top_p = 0
presence_penalty = 0
frequency_penalty = 0
completion(token, prompt, model, stop_sequences, maximum_tokens, best_of, temperature, top_k, top_p, presence_penalty, frequency_penalty)
x = getwd()
source_python("aa_client.py")
py_run_file(glue("{x}/aa_client.py"))
prompt = "How are you"
model = "luminous-base"
stop_sequences ="###"
maximum_tokens = as.integer(33)
typeof(maximum_tokens)
best_of = as.integer(1)
temperature = 0
n = as.integer(0)
top_k = as.integer(0)
top_p = 0
presence_penalty = 0
frequency_penalty = 0
completion(token, prompt, model, stop_sequences, maximum_tokens, best_of, temperature, top_k, top_p, presence_penalty, frequency_penalty, n)
reticulate::py_last_error()
prompt = "How are you"
model = "luminous-base"
stop_sequences ="###"
maximum_tokens = as.integer(33)
typeof(maximum_tokens)
best_of = as.integer(2)
temperature = 0
n = as.integer(1)
top_k = as.integer(0)
top_p = 0
presence_penalty = 0
frequency_penalty = 0
completion(token, prompt, model, stop_sequences, maximum_tokens, best_of, temperature, top_k, top_p, presence_penalty, frequency_penalty, n)
completion(token, prompt, model, stop_sequences, maximum_tokens, best_of, temperature, top_k, top_p, presence_penalty, frequency_penalty, n)
list = aa_completion(token = token,
prompt = "Q: How are you?",
model = "luminous-base",
browser(),
maximum_tokens = 1,
best_of = 2)
token = "eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJ1c2VyX2lkIjo0MjcyLCJ0b2tlbl9pZCI6MjgxMX0.k1PwaELDM-EKCWq9gPwkgtWA6bdo50gzoFb8Q3lOobk"
list = aa_completion(token = token,
prompt = "Q: How are you?",
model = "luminous-base",
maximum_tokens = 1,
best_of = 2)
$ deactivate
$ deactivate
deactivate
list = aa_completion(token = token,
prompt = "Q: How are you?",
model = "luminous-base",
maximum_tokens = 1,
best_of = 2)
list
list = aa_completion(token = token,
prompt = "Q: How are you?",
model = "luminous-base",
stop_sequences  ="###",
maximum_tokens = 1,
best_of = 2)
list = aa_completion(token = token,
prompt = "Q: How are you?",
model = "luminous-base",
stop_sequences  = c("###"),
maximum_tokens = 1,
best_of = 2)
text = completion(token, prompt, model, stop_sequences, maximum_tokens, best_of, temperature, top_k, top_p, presence_penalty, frequency_penalty, n)
n = input$slider_bestof
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
reticulate::py_last_error()
runApp()
runApp()
library(reticulate)
x = getwd()
source_python("aa_client.py")
py_run_file(glue("{x}/aa_client.py"))
prompt = "How are you"
model = "luminous-base"
stop_sequences ="###"
maximum_tokens = as.integer(33)
typeof(maximum_tokens)
best_of = as.integer(2)
temperature = 0
n = as.integer(1)
top_k = as.integer(0)
top_p = 0
presence_penalty = 0
frequency_penalty = 0
text = completion(token, prompt, model, stop_sequences, maximum_tokens, best_of, temperature, top_k, top_p, presence_penalty, frequency_penalty, n)
text
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
test = "Q: How are you?
###
A:"
prompt = gsub("[\r\n]", "", test)input$text_prompt
prompt = gsub("[\r\n]", "", test)
prompt
test = "Q: How are you?
###
A:"
test
runApp()
runApp()
runApp()
runApp()
text ="Q: what is love?
###
A:"
text
prompt = gsub("[\r\n]", "", text)
prompt
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
update.packages(ask = FALSE, checkBuilt = TRUE)
tinytex::tlmgr_update()
tinytex::tlmgr_update()
tinytex::reinstall_tinytex()
tinytex::reinstall_tinytex()
install.packages("tinytex")
install.packages("tinytex")
tinytex::tlmgr_update()
options(tinytex.verbose = TRUE)
shiny::runApp()
runApp()
runApp()
runApp()
runApp()
tinytex::install_tinytex()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
df = data.frame(Parameter_name, Parameter_setting)
first_column = c("Model","Max tokens","Best of","Temperature","Top k","Top p","Presency penalty","Frequency penalty")
scond_column = c()
df = data.frame(first_column, scond_column)
df = data.frame(first_column)
df
first_column = c("Model","Max tokens","Best of","Temperature","Top k","Top p","Presency penalty","Frequency penalty")
scond_column = c(input$select_model,as.integer(input$num_maxtoken),as.integer(input$slider_bestof),input$slider_temperature,
as.integer(input$slider_topk),input$slider_topp,input$slider_presence,input$slider_frequency)
df = data.frame(first_column)
runApp()
runApp()
runApp()
shiny::runApp()
library(reticulate)
runApp()
runApp()
runApp()
runApp()
model_price = matrix(c(0.006, 0.009, 0.035,
0.0075, 0.01125, 0.04375
), ncol=1, byrow=TRUE)
model_price
colnames(model_price) = c('price per 1.000 token')
rownames(model_price) <- c('luminous-base','luminous-extended','luminous-supreme',
'luminous-base-control','luminous-extended-control','luminous-supreme-control')
task_factor = matrix(c(1.0, 1.1, 1.3,
1.1, 1.1, NULL
), ncol=2, byrow=TRUE)
task_factor
task_factor = as.table(task_factor)
colnames(task_factor) = c('input','output')
rownames(task_factor) = c('complete','evaluate','embed')
task_factor
model_price
task_factor = cbind(
c(1.0, 1.1, 1.3),
c(1.1, 1.1, NULL)
)
task_factor
task_factor = cbind(
c(1.0, 1.1, 1.3),
c(1.1, 1.1, "")
)
task_factor
task_factor = as.table(cbind(
c(1.0, 1.1, 1.3),
c(1.1, 1.1, "")
))
task_factor
task_factor = as.table(task_factor)
colnames(task_factor) = c('input','output')
rownames(task_factor) = c('complete','evaluate','embed')
task_factor
runApp()
